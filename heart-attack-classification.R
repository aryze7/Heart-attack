library(chron)
library(tidyverse)
library(tidyr)
library(dplyr)
library(plyr)
library(ggplot2)
library(ggthemes)
library(ggpubr)
library(varhandle)
library(plotly)
library(matrixStats)
library(corrplot)
library(caret)
library(caTools)
library(GGally)
library(Hmisc)
library(PerformanceAnalytics)
library(mltools)
library(data.table)
library(gghighlight)
library(tibble)
library(rpart)
library(randomForest)
library(xgboost)
heart = read.csv("D:/JUPYTER/Projects/heart-attack/heart.csv")
view(heart)
colSums(is.na(heart))
head(heart)
tail(heart)
glimpse(heart)
ncol(heart)
nrow(heart)
colnames(heart)
summary(heart)

##############checking skewness of variables#########
summary(heart)
hist(heart$trtbps)
hist(heart$chol)
hist(heart$thalachh)
hist(heart$oldpeak)
hist(heart$age)

#######Applying log transformations for highly skewed vairables##################
heart$trtbps = log10(heart$trtbps)
summary(heart$trtbps)
hist(heart$trtbps)

heart$chol = log10(heart$chol)
summary(heart$chol)
hist(heart$chol)

heart$oldpeak = log10(heart$oldpeak+1)
summary(heart$oldpeak)
hist(heart$oldpeak)

heart$output = as.factor(as.character(heart$output, levels = c("0","1"), labels = c("0","1")))

#################RANDOM-FOREST#########################
set.seed(777)
split = sample.split(heart$output, SplitRatio = 0.8)
train_set = subset(heart,split == TRUE)
test_set = subset(heart,split == FALSE)

train_set[1:13] = scale(train_set[1:13])
test_set[1:13] = scale(test_set[1:13])

rf = randomForest(x = train_set[1:13], y = train_set$output)
test_set$predicted_rf.output = predict(rf, test_set[1:13])
accuracy_rf = mean(test_set$predicted_rf.output == test_set$output)
print(accuracy_rf)
##################XGBOOST##################

set.seed(777)
split = sample.split(heart$output, SplitRatio = 0.8)
training_set = subset(heart,split == TRUE)
testing_set = subset(heart,split == FALSE)
training_set$output = as.integer(as.character(training_set$output))

xgboost_classifier = xgboost(data = as.matrix(training_set[1:13]), label = training_set$output, nrounds = 25,objective = "binary:logistic")
pred = predict(xgboost_classifier, as.matrix(testing_set[1:13]))
testing_set$pred_xgboost = as.numeric(pred>0.5)
accuracy_xg = mean(as.integer(as.character(testing_set$pred_xgboost)) == testing_set$output)
print(accuracy_xg)
